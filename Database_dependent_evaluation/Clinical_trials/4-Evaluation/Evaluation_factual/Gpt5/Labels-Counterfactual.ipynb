{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a8cc5ed-1172-4518-acdf-7d6bc6a4ac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('transform_evaluation_files.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "def transform_file(input_file_path, output_dir, stats):\n",
    "    \"\"\"\n",
    "    Transform a single JSON file into question-organized format\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the input file\n",
    "        with open(input_file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Get the base filename without extension\n",
    "        base_filename = os.path.splitext(os.path.basename(input_file_path))[0]\n",
    "        \n",
    "        # Initialize output dictionary\n",
    "        output_data = {}\n",
    "        \n",
    "        # Process each question\n",
    "        for question_key, question_data in data.items():\n",
    "            if isinstance(question_data, dict) and 'statement' in question_data and 'label' in question_data:\n",
    "                # Transform label to eval_databases format\n",
    "                label = question_data['label'].lower().strip()\n",
    "                if label == 'yes':\n",
    "                    eval_value = 'hallucination'\n",
    "                elif label == 'no':\n",
    "                    eval_value = 'fact'\n",
    "                else:\n",
    "                    eval_value = 'N/A'\n",
    "                \n",
    "                # Update statistics\n",
    "                stats['total'][eval_value] += 1\n",
    "                stats['by_question'][question_key][eval_value] += 1\n",
    "                \n",
    "                # Create question structure with both keys\n",
    "                output_data[question_key] = {\n",
    "                    \"answer\": question_data['statement'],\n",
    "                    \"eval_databases\": eval_value\n",
    "                }\n",
    "        \n",
    "        # Save combined file\n",
    "        output_path = os.path.join(output_dir, f\"{base_filename}.json\")\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(output_data, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        logging.info(f\"✅ Transformed {base_filename}.json -> question-organized format\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Error processing {input_file_path}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def print_statistics(stats):\n",
    "    \"\"\"\n",
    "    Print detailed statistics about facts and hallucinations\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"📊 STATISTICS SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Total statistics\n",
    "    total_facts = stats['total']['fact']\n",
    "    total_hallucinations = stats['total']['hallucination']\n",
    "    total_na = stats['total']['N/A']\n",
    "    total_all = total_facts + total_hallucinations + total_na\n",
    "    \n",
    "    print(f\"🔢 TOTAL ACROSS ALL FILES:\")\n",
    "    print(f\"   ✅ Facts: {total_facts}\")\n",
    "    print(f\"   ❌ Hallucinations: {total_hallucinations}\")\n",
    "    print(f\"   ❓ N/A: {total_na}\")\n",
    "    print(f\"   📋 Total: {total_all}\")\n",
    "    \n",
    "    if total_all > 0:\n",
    "        fact_percentage = (total_facts / total_all) * 100\n",
    "        hallucination_percentage = (total_hallucinations / total_all) * 100\n",
    "        print(f\"   📈 Fact Rate: {fact_percentage:.1f}%\")\n",
    "        print(f\"   📉 Hallucination Rate: {hallucination_percentage:.1f}%\")\n",
    "    \n",
    "    # By question statistics\n",
    "    print(f\"\\n📋 BY QUESTION:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Question':<10} {'Facts':<8} {'Halluc.':<8} {'N/A':<6} {'Total':<8} {'Fact %':<8}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Sort questions naturally (Q1, Q2, ..., Q10, Q11, ...)\n",
    "    sorted_questions = sorted(stats['by_question'].keys(), \n",
    "                            key=lambda x: int(x[1:]) if x[1:].isdigit() else 999)\n",
    "    \n",
    "    for question in sorted_questions:\n",
    "        q_stats = stats['by_question'][question]\n",
    "        q_facts = q_stats['fact']\n",
    "        q_halluc = q_stats['hallucination']\n",
    "        q_na = q_stats['N/A']\n",
    "        q_total = q_facts + q_halluc + q_na\n",
    "        \n",
    "        if q_total > 0:\n",
    "            q_fact_pct = (q_facts / q_total) * 100\n",
    "            print(f\"{question:<10} {q_facts:<8} {q_halluc:<8} {q_na:<6} {q_total:<8} {q_fact_pct:<7.1f}%\")\n",
    "        else:\n",
    "            print(f\"{question:<10} {q_facts:<8} {q_halluc:<8} {q_na:<6} {q_total:<8} {'N/A':<8}\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "\n",
    "def process_folder(input_folder, output_dir):\n",
    "    \"\"\"\n",
    "    Process all JSON files in the input folder\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Initialize statistics\n",
    "        stats = {\n",
    "            'total': defaultdict(int),\n",
    "            'by_question': defaultdict(lambda: defaultdict(int))\n",
    "        }\n",
    "        \n",
    "        # Find all JSON files in the input folder\n",
    "        json_files = glob.glob(os.path.join(input_folder, \"*.json\"))\n",
    "        \n",
    "        if not json_files:\n",
    "            logging.warning(f\"No JSON files found in {input_folder}\")\n",
    "            return\n",
    "        \n",
    "        logging.info(f\"Found {len(json_files)} JSON files to process\")\n",
    "        \n",
    "        # Process each file\n",
    "        successful = 0\n",
    "        failed = 0\n",
    "        \n",
    "        for json_file in tqdm(json_files, desc=\"Processing files\"):\n",
    "            if transform_file(json_file, output_dir, stats):\n",
    "                successful += 1\n",
    "            else:\n",
    "                failed += 1\n",
    "        \n",
    "        # Print processing summary\n",
    "        logging.info(f\"Processing complete!\")\n",
    "        logging.info(f\"✅ Successfully processed: {successful} files\")\n",
    "        logging.info(f\"❌ Failed to process: {failed} files\")\n",
    "        logging.info(f\"📁 Output files saved to: {output_dir}\")\n",
    "        \n",
    "        # Print detailed statistics\n",
    "        print_statistics(stats)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing folder: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    # Configuration\n",
    "    input_folder = \"Database_dependent_evaluation/Clinical_trials/4-Evaluation/Evaluation_counterfactual/Gpt5/Paragraph_level/Evaluation_title_Paragraph_GPT\"  # Replace with your input folder path\n",
    "    output_dir =   \"Database_dependent_evaluation/Clinical_trials/5-Labels/Inference_files_with_labels_Counterfactual/Gpt5/Paragraph_level/Inference_title_Paragraph\"  # Replace with your output folder path\n",
    "    \n",
    "    # Print configuration\n",
    "    print(\"🔄 Evaluation Files Transformer\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"📁 Input folder: {input_folder}\")\n",
    "    print(f\"📁 Output folder: {output_dir}\")\n",
    "    print(\"🔄 Output format:\")\n",
    "    print(\"   {\")\n",
    "    print('     \"Q1\": {')\n",
    "    print('       \"answer\": \"statement text...\",')\n",
    "    print('       \"eval_databases\": \"fact/hallucination\"')\n",
    "    print('     },')\n",
    "    print('     \"Q2\": {')\n",
    "    print('       \"answer\": \"statement text...\",')\n",
    "    print('       \"eval_databases\": \"fact/hallucination\"')\n",
    "    print('     }')\n",
    "    print(\"   }\")\n",
    "    print(\"🔄 Transformation rules:\")\n",
    "    print(\"   - statement → answer\")\n",
    "    print(\"   - label 'no' → eval_databases = 'fact'\")\n",
    "    print(\"   - label 'yes' → eval_databases = 'hallucination'\")\n",
    "    print(\"   - other labels → eval_databases = 'N/A'\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Process the folder\n",
    "    process_folder(input_folder, output_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59af4037-362a-427c-ac7e-c753af2e364e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
