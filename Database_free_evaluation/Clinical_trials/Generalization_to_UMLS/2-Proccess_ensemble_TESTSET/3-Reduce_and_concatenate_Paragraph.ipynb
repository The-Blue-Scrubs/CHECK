{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f6a0207-4cd6-4782-b568-5d972d2f2cfb",
   "metadata": {},
   "source": [
    "## Here we reduce and concatenate the stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5445748e-6fea-4172-82a7-c55c5867bde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 140 CSV files to process\n",
      "Output will have 681 columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 140/140 [00:15<00:00,  8.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 140 CSV files to concatenate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 140/140 [00:00<00:00, 151.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final DataFrame info:\n",
      "Shape: (140, 683)\n",
      "Number of samples: 140\n",
      "Number of features: 683\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "fact             77\n",
      "hallucination    63\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_fixed_column_names():\n",
    "    \"\"\"\n",
    "    Generate a fixed list of column names to ensure consistency across all files\n",
    "    \"\"\"\n",
    "    columns = []\n",
    "    \n",
    "    # Models (excluding model_5)\n",
    "    models = [f\"model_{i}\" for i in range(1, 7) if i != 5]\n",
    "    \n",
    "    # Metrics for each model\n",
    "    metrics = ['gold_lp', 'rank', 'Entropy', 'gold_lp_cumsum', 'gold_prob', 'gold_lp_normalized']\n",
    "    \n",
    "    # Statistics to compute\n",
    "    stats = ['median', 'max', 'min', 'std', \n",
    "             'moment1', 'moment2', 'moment3', 'moment4', 'moment5', \n",
    "             'q95', 'q90', 'q85', 'q80', 'q20', 'q15', 'q10', 'q05']\n",
    "    \n",
    "    # Generate columns for model metrics\n",
    "    for model in models:\n",
    "        for metric in metrics:\n",
    "            for stat in stats:\n",
    "                columns.append(f\"{model}_{metric}_{stat}\")\n",
    "    \n",
    "    # Generate columns for KL divergence terms\n",
    "    model_pairs = [(i, j) for i in range(1, 7) for j in range(i+1, 7) \n",
    "                  if i != 5 and j != 5]\n",
    "    \n",
    "    for i, j in model_pairs:\n",
    "        for stat in stats:\n",
    "            columns.append(f\"kl_{i}_vs_{j}_{stat}\")\n",
    "    \n",
    "    return columns\n",
    "\n",
    "def get_label_from_json(trial_name, question_number, label_folder_path):\n",
    "    \"\"\"\n",
    "    Get label from corresponding JSON file and return 'fact' or 'hallucination'\n",
    "    based on the 'statement' field\n",
    "    \n",
    "    Args:\n",
    "        trial_name: Name of the trial (e.g., 'NCT001')\n",
    "        question_number: Question number (1-7)\n",
    "        label_folder_path: Path to the folder containing JSON files\n",
    "    \n",
    "    Returns:\n",
    "        str: 'fact' if statement is True, 'hallucination' if False, None if error\n",
    "    \"\"\"\n",
    "    if not label_folder_path:  # If no path provided\n",
    "        return None\n",
    "        \n",
    "    json_path = os.path.join(\n",
    "        label_folder_path,\n",
    "        f\"{trial_name}.json\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        with open(json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "            # Get statement value\n",
    "            statement = data.get('statement')\n",
    "            \n",
    "            # Return appropriate label\n",
    "            if statement == 'True':\n",
    "                return 'fact'\n",
    "            elif statement == 'False':\n",
    "                return 'hallucination'\n",
    "            else:\n",
    "                print(f\"Warning: Unknown statement value in {trial_name}: {statement}\")\n",
    "                return None\n",
    "                \n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {json_path}\")\n",
    "        return None\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Invalid JSON in file: {json_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading JSON for {trial_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_trial_and_question(file_path):\n",
    "    \"\"\"\n",
    "    Extract trial name and question number from file path\n",
    "    Example: path/to/NCT00001959/logprob_matrix_1.csv -> (\"NCT00001959\", 1)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get filename and remove extension\n",
    "        filename = os.path.basename(file_path)\n",
    "        # Extract question number\n",
    "        question_num = int(filename.split('_')[-1].split('.')[0])\n",
    "        # Extract trial name from path\n",
    "        trial_name = file_path.split('/')[-2]  # Adjust this based on your actual path structure\n",
    "        return trial_name, question_num\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting trial and question from {file_path}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def compute_statistics(series):\n",
    "    \"\"\"\n",
    "    Compute various statistical measures for a series\n",
    "    \"\"\"\n",
    "    mean = series.mean()\n",
    "    \n",
    "    stats = {\n",
    "        'median': series.median(),\n",
    "        'max': series.max(),\n",
    "        'min': series.min(),\n",
    "        'std': series.std(),\n",
    "        \n",
    "        # Central moments\n",
    "        'moment1': mean,\n",
    "        'moment2': ((series - mean) ** 2).mean(),\n",
    "        'moment3': ((series - mean) ** 3).mean(),\n",
    "        'moment4': ((series - mean) ** 4).mean(),\n",
    "        'moment5': ((series - mean) ** 5).mean(),\n",
    "        \n",
    "        # Existing quantiles\n",
    "        'q95': series.quantile(0.95),\n",
    "        'q90': series.quantile(0.90),\n",
    "        'q85': series.quantile(0.85),\n",
    "        'q80': series.quantile(0.80),\n",
    "        'q20': series.quantile(0.20),\n",
    "        'q15': series.quantile(0.15),\n",
    "        'q10': series.quantile(0.10),\n",
    "        'q05': series.quantile(0.05),\n",
    "    }    \n",
    "    return stats\n",
    "\n",
    "def process_metrics_and_kl(input_folder, kl_folder, output_folder, label_folder_path=None):\n",
    "    \"\"\"\n",
    "    Process original metrics and KL divergence terms with consistent column ordering\n",
    "    \"\"\"\n",
    "    # Get fixed column names\n",
    "    fixed_columns = get_fixed_column_names()\n",
    "    \n",
    "    # Original metrics to analyze\n",
    "    metrics = ['gold_lp', 'rank', 'Entropy', 'gold_lp_cumsum', 'gold_prob', 'gold_lp_normalized']\n",
    "    \n",
    "    # Get all CSV files from model1 directory\n",
    "    csv_files = []\n",
    "    model1_path = os.path.join(input_folder, \"model_1\")\n",
    "    for root, dirs, files in os.walk(model1_path):\n",
    "        # Skip hidden directories\n",
    "        dirs[:] = [d for d in dirs if not d.startswith('.')]\n",
    "        \n",
    "        for file in files:\n",
    "            if not file.startswith('.') and file.endswith('.csv'):\n",
    "                csv_files.append((os.path.join(root, file), file))\n",
    "    \n",
    "    print(f\"Found {len(csv_files)} CSV files to process\")\n",
    "    print(f\"Output will have {len(fixed_columns) + 1} columns\")  # +1 for label\n",
    "    \n",
    "    for file_path1, file_name in tqdm(csv_files, desc=\"Processing files\"):\n",
    "        try:\n",
    "            # Get trial name and question number\n",
    "            trial_name, question_num = extract_trial_and_question(file_path1)\n",
    "            \n",
    "            if trial_name and question_num and label_folder_path:\n",
    "                # Get label from JSON only if path is provided\n",
    "                label = get_label_from_json(trial_name, question_num, label_folder_path)\n",
    "            else:\n",
    "                label = None\n",
    "            \n",
    "            # Dictionary to store all metrics\n",
    "            all_stats = {col: np.nan for col in fixed_columns}  # Initialize with NaN\n",
    "            \n",
    "            # Add label column\n",
    "            all_stats['label'] = label\n",
    "            \n",
    "            # Process each model (excluding model_5)\n",
    "            models = [f\"model_{i}\" for i in range(1, 7) if i != 5]\n",
    "            \n",
    "            # Step 1: Process original metrics for each model\n",
    "            for model in models:\n",
    "                file_path = os.path.join(input_folder, model, os.path.relpath(file_path1, model1_path))\n",
    "                if not os.path.exists(file_path):\n",
    "                    print(f\"Skipping {file_name} - no matching file in {model}\")\n",
    "                    continue\n",
    "                \n",
    "                df = pd.read_csv(file_path)\n",
    "                \n",
    "                # Compute statistics for each metric\n",
    "                for metric in metrics:\n",
    "                    if metric in df.columns:\n",
    "                        stats = compute_statistics(df[metric])\n",
    "                        for stat_name, value in stats.items():\n",
    "                            col_name = f\"{model}_{metric}_{stat_name}\"\n",
    "                            all_stats[col_name] = value\n",
    "            \n",
    "            # Step 2: Process KL divergence terms\n",
    "            kl_file_path = os.path.join(kl_folder, os.path.relpath(file_path1, model1_path))\n",
    "            if os.path.exists(kl_file_path):\n",
    "                kl_df = pd.read_csv(kl_file_path)\n",
    "                \n",
    "                # Get all KL columns\n",
    "                kl_cols = [col for col in kl_df.columns if col.startswith('kl_')]\n",
    "                \n",
    "                # Compute statistics for each KL term\n",
    "                for kl_col in kl_cols:\n",
    "                    stats = compute_statistics(kl_df[kl_col])\n",
    "                    for stat_name, value in stats.items():\n",
    "                        col_name = f\"{kl_col}_{stat_name}\"\n",
    "                        all_stats[col_name] = value\n",
    "            \n",
    "            # Create output DataFrame with fixed column order plus label\n",
    "            columns_with_label = fixed_columns + ['label']\n",
    "            result_df = pd.DataFrame([all_stats])[columns_with_label]\n",
    "            \n",
    "            # Create output directory structure\n",
    "            output_file_path = os.path.join(output_folder, os.path.relpath(file_path1, model1_path))\n",
    "            os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "            \n",
    "            # Save results\n",
    "            result_df.to_csv(output_file_path, index=False)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing {file_name}:\")\n",
    "            print(f\"Error type: {type(e)}\")\n",
    "            print(f\"Error message: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "def concatenate_output_files(output_folder):\n",
    "    \"\"\"\n",
    "    Concatenate all CSV files in Output_folder and its subfolders into a single DataFrame\n",
    "    \"\"\"\n",
    "    # Get list of all CSV files\n",
    "    csv_files = []\n",
    "    for root, dirs, files in os.walk(output_folder):\n",
    "        # Skip hidden directories\n",
    "        dirs[:] = [d for d in dirs if not d.startswith('.')]\n",
    "        \n",
    "        for file in files:\n",
    "            if not file.startswith('.') and file.endswith('.csv'):\n",
    "                csv_files.append((os.path.join(root, file), file))\n",
    "    \n",
    "    print(f\"Found {len(csv_files)} CSV files to concatenate\")\n",
    "    # Sort files alphabetically\n",
    "    csv_files = sorted(csv_files)\n",
    "    \n",
    "    # Read and concatenate all files\n",
    "    all_dfs = []\n",
    "    for file_path, file_name in tqdm(csv_files, desc=\"Reading files\"):\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Add filename as a column (optional but useful for tracking)\n",
    "            df['source_file'] = file_name\n",
    "            \n",
    "            # Add full path as a column (optional)\n",
    "            df['file_path'] = os.path.relpath(file_path, output_folder)\n",
    "            \n",
    "            all_dfs.append(df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError reading {file_name}:\")\n",
    "            print(f\"Error type: {type(e)}\")\n",
    "            print(f\"Error message: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Concatenate all DataFrames\n",
    "    if all_dfs:\n",
    "        final_df = pd.concat(all_dfs, ignore_index=True)\n",
    "        \n",
    "        # Print some information about the final DataFrame\n",
    "        print(\"\\nFinal DataFrame info:\")\n",
    "        print(f\"Shape: {final_df.shape}\")\n",
    "        print(f\"Number of samples: {len(final_df)}\")\n",
    "        print(f\"Number of features: {len(final_df.columns)}\")\n",
    "        \n",
    "        if 'label' in final_df.columns:\n",
    "            print(\"\\nLabel distribution:\")\n",
    "            print(final_df['label'].value_counts())\n",
    "        \n",
    "        return final_df\n",
    "    else:\n",
    "        print(\"No files were successfully read!\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Paths\n",
    "    input_folder = \"Database_free_evaluation/Clinical_trials/Generalization_to_UMLS/files_with_labels\"\n",
    "    kl_folder = \"kl_analysis_Paragraph_title_features\"\n",
    "    output_folder = \"Output_folder_Paragraph_title\"\n",
    "\n",
    "     # Label folder path (set to None if not using labels)\n",
    "    label_folder_path = \"Database_free_evaluation/Clinical_trials/Generalization_to_UMLS/files_with_labels\"\n",
    "    # Or for other folders:\n",
    "    # label_folder_path = None\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Step 1: Process files and create individual outputs\n",
    "    process_metrics_and_kl(input_folder, kl_folder, output_folder, label_folder_path)\n",
    "\n",
    "    # Step 2: Concatenate all output files\n",
    "    final_df = concatenate_output_files(output_folder)\n",
    "    \n",
    "    # Optional: Save concatenated DataFrame\n",
    "    if final_df is not None:\n",
    "        final_df.to_csv(\"concatenated_results_Paragraph_title_TESTSET.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa8f55d-5f71-4255-b188-02cbed45b642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccab0e6f-224e-483e-b3d5-967756182838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_1_gold_lp_median</th>\n",
       "      <th>model_1_gold_lp_max</th>\n",
       "      <th>model_1_gold_lp_min</th>\n",
       "      <th>model_1_gold_lp_std</th>\n",
       "      <th>model_1_gold_lp_moment1</th>\n",
       "      <th>model_1_gold_lp_moment2</th>\n",
       "      <th>model_1_gold_lp_moment3</th>\n",
       "      <th>model_1_gold_lp_moment4</th>\n",
       "      <th>model_1_gold_lp_moment5</th>\n",
       "      <th>model_1_gold_lp_q95</th>\n",
       "      <th>...</th>\n",
       "      <th>kl_4_vs_6_q90</th>\n",
       "      <th>kl_4_vs_6_q85</th>\n",
       "      <th>kl_4_vs_6_q80</th>\n",
       "      <th>kl_4_vs_6_q20</th>\n",
       "      <th>kl_4_vs_6_q15</th>\n",
       "      <th>kl_4_vs_6_q10</th>\n",
       "      <th>kl_4_vs_6_q05</th>\n",
       "      <th>label</th>\n",
       "      <th>source_file</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.101243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>7.957377</td>\n",
       "      <td>-1.913819</td>\n",
       "      <td>62.949561</td>\n",
       "      <td>-5558.486186</td>\n",
       "      <td>5.418419e+05</td>\n",
       "      <td>-5.310102e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338867</td>\n",
       "      <td>0.284243</td>\n",
       "      <td>0.233684</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>2.611358e-06</td>\n",
       "      <td>1.495094e-07</td>\n",
       "      <td>fact</td>\n",
       "      <td>logprob_matrix_1.csv</td>\n",
       "      <td>NCT001/logprob_matrix_1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.184389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>13.725313</td>\n",
       "      <td>-3.043246</td>\n",
       "      <td>186.590078</td>\n",
       "      <td>-17353.034953</td>\n",
       "      <td>1.683384e+06</td>\n",
       "      <td>-1.632044e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.436939</td>\n",
       "      <td>0.388627</td>\n",
       "      <td>0.332166</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>3.916730e-06</td>\n",
       "      <td>1.558375e-06</td>\n",
       "      <td>fact</td>\n",
       "      <td>logprob_matrix_2.csv</td>\n",
       "      <td>NCT001/logprob_matrix_2.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.104828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.088431</td>\n",
       "      <td>2.282414</td>\n",
       "      <td>-1.248971</td>\n",
       "      <td>5.184127</td>\n",
       "      <td>-27.636514</td>\n",
       "      <td>2.170131e+02</td>\n",
       "      <td>-1.708334e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.433736</td>\n",
       "      <td>0.359820</td>\n",
       "      <td>0.302641</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.354503e-06</td>\n",
       "      <td>2.581271e-07</td>\n",
       "      <td>fact</td>\n",
       "      <td>logprob_matrix_3.csv</td>\n",
       "      <td>NCT001/logprob_matrix_3.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.622008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>18.048238</td>\n",
       "      <td>-4.981273</td>\n",
       "      <td>323.522998</td>\n",
       "      <td>-29113.051509</td>\n",
       "      <td>2.772982e+06</td>\n",
       "      <td>-2.634489e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466100</td>\n",
       "      <td>0.358624</td>\n",
       "      <td>0.290390</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>1.018734e-05</td>\n",
       "      <td>2.189004e-06</td>\n",
       "      <td>fact</td>\n",
       "      <td>logprob_matrix_4.csv</td>\n",
       "      <td>NCT001/logprob_matrix_4.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.093424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>11.988374</td>\n",
       "      <td>-2.726284</td>\n",
       "      <td>143.039976</td>\n",
       "      <td>-13106.080152</td>\n",
       "      <td>1.273347e+06</td>\n",
       "      <td>-1.238311e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451976</td>\n",
       "      <td>0.352293</td>\n",
       "      <td>0.276769</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1.076772e-06</td>\n",
       "      <td>1.921327e-07</td>\n",
       "      <td>fact</td>\n",
       "      <td>logprob_matrix_5.csv</td>\n",
       "      <td>NCT001/logprob_matrix_5.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.091860</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>11.153900</td>\n",
       "      <td>-2.566233</td>\n",
       "      <td>123.664509</td>\n",
       "      <td>-11143.041393</td>\n",
       "      <td>1.080548e+06</td>\n",
       "      <td>-1.051829e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523077</td>\n",
       "      <td>0.436182</td>\n",
       "      <td>0.291353</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>2.349377e-06</td>\n",
       "      <td>1.149221e-06</td>\n",
       "      <td>fact</td>\n",
       "      <td>logprob_matrix_6.csv</td>\n",
       "      <td>NCT001/logprob_matrix_6.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.258901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>11.028911</td>\n",
       "      <td>-2.619402</td>\n",
       "      <td>120.904130</td>\n",
       "      <td>-11129.397208</td>\n",
       "      <td>1.083574e+06</td>\n",
       "      <td>-1.055083e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456004</td>\n",
       "      <td>0.299129</td>\n",
       "      <td>0.229714</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>2.907773e-06</td>\n",
       "      <td>2.513672e-07</td>\n",
       "      <td>fact</td>\n",
       "      <td>logprob_matrix_7.csv</td>\n",
       "      <td>NCT001/logprob_matrix_7.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.137985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.018279</td>\n",
       "      <td>2.386667</td>\n",
       "      <td>-1.367059</td>\n",
       "      <td>5.663443</td>\n",
       "      <td>-32.286110</td>\n",
       "      <td>3.124747e+02</td>\n",
       "      <td>-3.400800e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.446325</td>\n",
       "      <td>0.370710</td>\n",
       "      <td>0.308631</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>4.433990e-05</td>\n",
       "      <td>2.830322e-06</td>\n",
       "      <td>fact</td>\n",
       "      <td>logprob_matrix_1.csv</td>\n",
       "      <td>NCT004/logprob_matrix_1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.095941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>15.827896</td>\n",
       "      <td>-3.482843</td>\n",
       "      <td>248.916381</td>\n",
       "      <td>-23034.624587</td>\n",
       "      <td>2.225294e+06</td>\n",
       "      <td>-2.147627e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396432</td>\n",
       "      <td>0.308901</td>\n",
       "      <td>0.203338</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>2.669943e-05</td>\n",
       "      <td>1.320989e-06</td>\n",
       "      <td>fact</td>\n",
       "      <td>logprob_matrix_2.csv</td>\n",
       "      <td>NCT004/logprob_matrix_2.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.258093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-17.096836</td>\n",
       "      <td>2.584134</td>\n",
       "      <td>-1.460670</td>\n",
       "      <td>6.642414</td>\n",
       "      <td>-48.760314</td>\n",
       "      <td>5.752645e+02</td>\n",
       "      <td>-7.353554e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389190</td>\n",
       "      <td>0.298376</td>\n",
       "      <td>0.255989</td>\n",
       "      <td>0.003489</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>1.010066e-05</td>\n",
       "      <td>1.504882e-06</td>\n",
       "      <td>fact</td>\n",
       "      <td>logprob_matrix_3.csv</td>\n",
       "      <td>NCT004/logprob_matrix_3.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.121029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>14.740621</td>\n",
       "      <td>-3.426294</td>\n",
       "      <td>215.688226</td>\n",
       "      <td>-19859.335667</td>\n",
       "      <td>1.918979e+06</td>\n",
       "      <td>-1.853017e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509153</td>\n",
       "      <td>0.432986</td>\n",
       "      <td>0.360882</td>\n",
       "      <td>0.003506</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>9.252099e-06</td>\n",
       "      <td>2.927935e-07</td>\n",
       "      <td>fact</td>\n",
       "      <td>logprob_matrix_4.csv</td>\n",
       "      <td>NCT004/logprob_matrix_4.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.376020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>10.072656</td>\n",
       "      <td>-2.538589</td>\n",
       "      <td>100.961063</td>\n",
       "      <td>-9099.910784</td>\n",
       "      <td>8.848968e+05</td>\n",
       "      <td>-8.621426e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.481737</td>\n",
       "      <td>0.378353</td>\n",
       "      <td>0.306145</td>\n",
       "      <td>0.007227</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>9.766759e-05</td>\n",
       "      <td>2.466392e-06</td>\n",
       "      <td>fact</td>\n",
       "      <td>logprob_matrix_5.csv</td>\n",
       "      <td>NCT004/logprob_matrix_5.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.455198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-14.262915</td>\n",
       "      <td>2.693901</td>\n",
       "      <td>-1.648934</td>\n",
       "      <td>7.216559</td>\n",
       "      <td>-49.273387</td>\n",
       "      <td>5.162261e+02</td>\n",
       "      <td>-5.572736e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.498120</td>\n",
       "      <td>0.359931</td>\n",
       "      <td>0.305831</td>\n",
       "      <td>0.004176</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>2.276741e-04</td>\n",
       "      <td>8.924300e-07</td>\n",
       "      <td>fact</td>\n",
       "      <td>logprob_matrix_6.csv</td>\n",
       "      <td>NCT004/logprob_matrix_6.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.042750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>14.570948</td>\n",
       "      <td>-3.241731</td>\n",
       "      <td>210.785098</td>\n",
       "      <td>-19536.396555</td>\n",
       "      <td>1.891856e+06</td>\n",
       "      <td>-1.830406e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.539506</td>\n",
       "      <td>0.392266</td>\n",
       "      <td>0.312678</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>5.591086e-07</td>\n",
       "      <td>8.553685e-08</td>\n",
       "      <td>fact</td>\n",
       "      <td>logprob_matrix_7.csv</td>\n",
       "      <td>NCT004/logprob_matrix_7.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.116461</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>7.220452</td>\n",
       "      <td>-1.717915</td>\n",
       "      <td>51.881845</td>\n",
       "      <td>-4627.338868</td>\n",
       "      <td>4.531122e+05</td>\n",
       "      <td>-4.451642e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.406174</td>\n",
       "      <td>0.323216</td>\n",
       "      <td>0.276092</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>5.696230e-06</td>\n",
       "      <td>7.487155e-07</td>\n",
       "      <td>fact</td>\n",
       "      <td>logprob_matrix_1.csv</td>\n",
       "      <td>NCT010/logprob_matrix_1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.077897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>13.883350</td>\n",
       "      <td>-3.171938</td>\n",
       "      <td>190.894078</td>\n",
       "      <td>-17476.247481</td>\n",
       "      <td>1.690957e+06</td>\n",
       "      <td>-1.636879e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454138</td>\n",
       "      <td>0.309697</td>\n",
       "      <td>0.251163</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>8.536300e-06</td>\n",
       "      <td>1.157843e-06</td>\n",
       "      <td>fact</td>\n",
       "      <td>logprob_matrix_2.csv</td>\n",
       "      <td>NCT010/logprob_matrix_2.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.161128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-16.911507</td>\n",
       "      <td>2.213241</td>\n",
       "      <td>-1.112270</td>\n",
       "      <td>4.869450</td>\n",
       "      <td>-41.940163</td>\n",
       "      <td>5.286866e+02</td>\n",
       "      <td>-7.228481e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.540271</td>\n",
       "      <td>0.420656</td>\n",
       "      <td>0.257652</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>1.347772e-05</td>\n",
       "      <td>3.984937e-07</td>\n",
       "      <td>fact</td>\n",
       "      <td>logprob_matrix_3.csv</td>\n",
       "      <td>NCT010/logprob_matrix_3.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.046798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>8.413240</td>\n",
       "      <td>-1.947634</td>\n",
       "      <td>70.313856</td>\n",
       "      <td>-6270.780810</td>\n",
       "      <td>6.124234e+05</td>\n",
       "      <td>-6.002475e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.390658</td>\n",
       "      <td>0.256812</td>\n",
       "      <td>0.193164</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>1.943385e-05</td>\n",
       "      <td>6.651712e-07</td>\n",
       "      <td>fact</td>\n",
       "      <td>logprob_matrix_4.csv</td>\n",
       "      <td>NCT010/logprob_matrix_4.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.099684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>9.260650</td>\n",
       "      <td>-2.091227</td>\n",
       "      <td>85.409604</td>\n",
       "      <td>-7694.128662</td>\n",
       "      <td>7.505644e+05</td>\n",
       "      <td>-7.345129e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368163</td>\n",
       "      <td>0.275869</td>\n",
       "      <td>0.228354</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>2.381714e-05</td>\n",
       "      <td>1.753440e-06</td>\n",
       "      <td>fact</td>\n",
       "      <td>logprob_matrix_5.csv</td>\n",
       "      <td>NCT010/logprob_matrix_5.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.089061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-14.930673</td>\n",
       "      <td>2.420302</td>\n",
       "      <td>-1.245588</td>\n",
       "      <td>5.824951</td>\n",
       "      <td>-40.330393</td>\n",
       "      <td>4.169366e+02</td>\n",
       "      <td>-4.613143e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414084</td>\n",
       "      <td>0.306181</td>\n",
       "      <td>0.233201</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>2.245046e-06</td>\n",
       "      <td>4.598620e-07</td>\n",
       "      <td>fact</td>\n",
       "      <td>logprob_matrix_6.csv</td>\n",
       "      <td>NCT010/logprob_matrix_6.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 683 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_1_gold_lp_median  model_1_gold_lp_max  model_1_gold_lp_min  \\\n",
       "0                -0.101243                  0.0          -100.000000   \n",
       "1                -0.184389                  0.0          -100.000000   \n",
       "2                -0.104828                  0.0           -10.088431   \n",
       "3                -0.622008                  0.0          -100.000000   \n",
       "4                -0.093424                  0.0          -100.000000   \n",
       "5                -0.091860                  0.0          -100.000000   \n",
       "6                -0.258901                  0.0          -100.000000   \n",
       "7                -0.137985                  0.0           -15.018279   \n",
       "8                -0.095941                  0.0          -100.000000   \n",
       "9                -0.258093                  0.0           -17.096836   \n",
       "10               -0.121029                  0.0          -100.000000   \n",
       "11               -0.376020                  0.0          -100.000000   \n",
       "12               -0.455198                  0.0           -14.262915   \n",
       "13               -0.042750                  0.0          -100.000000   \n",
       "14               -0.116461                  0.0          -100.000000   \n",
       "15               -0.077897                  0.0          -100.000000   \n",
       "16               -0.161128                  0.0           -16.911507   \n",
       "17               -0.046798                  0.0          -100.000000   \n",
       "18               -0.099684                  0.0          -100.000000   \n",
       "19               -0.089061                  0.0           -14.930673   \n",
       "\n",
       "    model_1_gold_lp_std  model_1_gold_lp_moment1  model_1_gold_lp_moment2  \\\n",
       "0              7.957377                -1.913819                62.949561   \n",
       "1             13.725313                -3.043246               186.590078   \n",
       "2              2.282414                -1.248971                 5.184127   \n",
       "3             18.048238                -4.981273               323.522998   \n",
       "4             11.988374                -2.726284               143.039976   \n",
       "5             11.153900                -2.566233               123.664509   \n",
       "6             11.028911                -2.619402               120.904130   \n",
       "7              2.386667                -1.367059                 5.663443   \n",
       "8             15.827896                -3.482843               248.916381   \n",
       "9              2.584134                -1.460670                 6.642414   \n",
       "10            14.740621                -3.426294               215.688226   \n",
       "11            10.072656                -2.538589               100.961063   \n",
       "12             2.693901                -1.648934                 7.216559   \n",
       "13            14.570948                -3.241731               210.785098   \n",
       "14             7.220452                -1.717915                51.881845   \n",
       "15            13.883350                -3.171938               190.894078   \n",
       "16             2.213241                -1.112270                 4.869450   \n",
       "17             8.413240                -1.947634                70.313856   \n",
       "18             9.260650                -2.091227                85.409604   \n",
       "19             2.420302                -1.245588                 5.824951   \n",
       "\n",
       "    model_1_gold_lp_moment3  model_1_gold_lp_moment4  model_1_gold_lp_moment5  \\\n",
       "0              -5558.486186             5.418419e+05            -5.310102e+07   \n",
       "1             -17353.034953             1.683384e+06            -1.632044e+08   \n",
       "2                -27.636514             2.170131e+02            -1.708334e+03   \n",
       "3             -29113.051509             2.772982e+06            -2.634489e+08   \n",
       "4             -13106.080152             1.273347e+06            -1.238311e+08   \n",
       "5             -11143.041393             1.080548e+06            -1.051829e+08   \n",
       "6             -11129.397208             1.083574e+06            -1.055083e+08   \n",
       "7                -32.286110             3.124747e+02            -3.400800e+03   \n",
       "8             -23034.624587             2.225294e+06            -2.147627e+08   \n",
       "9                -48.760314             5.752645e+02            -7.353554e+03   \n",
       "10            -19859.335667             1.918979e+06            -1.853017e+08   \n",
       "11             -9099.910784             8.848968e+05            -8.621426e+07   \n",
       "12               -49.273387             5.162261e+02            -5.572736e+03   \n",
       "13            -19536.396555             1.891856e+06            -1.830406e+08   \n",
       "14             -4627.338868             4.531122e+05            -4.451642e+07   \n",
       "15            -17476.247481             1.690957e+06            -1.636879e+08   \n",
       "16               -41.940163             5.286866e+02            -7.228481e+03   \n",
       "17             -6270.780810             6.124234e+05            -6.002475e+07   \n",
       "18             -7694.128662             7.505644e+05            -7.345129e+07   \n",
       "19               -40.330393             4.169366e+02            -4.613143e+03   \n",
       "\n",
       "    model_1_gold_lp_q95  ...  kl_4_vs_6_q90  kl_4_vs_6_q85  kl_4_vs_6_q80  \\\n",
       "0                   0.0  ...       0.338867       0.284243       0.233684   \n",
       "1                   0.0  ...       0.436939       0.388627       0.332166   \n",
       "2                   0.0  ...       0.433736       0.359820       0.302641   \n",
       "3                   0.0  ...       0.466100       0.358624       0.290390   \n",
       "4                   0.0  ...       0.451976       0.352293       0.276769   \n",
       "5                   0.0  ...       0.523077       0.436182       0.291353   \n",
       "6                   0.0  ...       0.456004       0.299129       0.229714   \n",
       "7                   0.0  ...       0.446325       0.370710       0.308631   \n",
       "8                   0.0  ...       0.396432       0.308901       0.203338   \n",
       "9                   0.0  ...       0.389190       0.298376       0.255989   \n",
       "10                  0.0  ...       0.509153       0.432986       0.360882   \n",
       "11                  0.0  ...       0.481737       0.378353       0.306145   \n",
       "12                  0.0  ...       0.498120       0.359931       0.305831   \n",
       "13                  0.0  ...       0.539506       0.392266       0.312678   \n",
       "14                  0.0  ...       0.406174       0.323216       0.276092   \n",
       "15                  0.0  ...       0.454138       0.309697       0.251163   \n",
       "16                  0.0  ...       0.540271       0.420656       0.257652   \n",
       "17                  0.0  ...       0.390658       0.256812       0.193164   \n",
       "18                  0.0  ...       0.368163       0.275869       0.228354   \n",
       "19                  0.0  ...       0.414084       0.306181       0.233201   \n",
       "\n",
       "    kl_4_vs_6_q20  kl_4_vs_6_q15  kl_4_vs_6_q10  kl_4_vs_6_q05  label  \\\n",
       "0        0.000101       0.000022   2.611358e-06   1.495094e-07   fact   \n",
       "1        0.000051       0.000024   3.916730e-06   1.558375e-06   fact   \n",
       "2        0.000017       0.000004   1.354503e-06   2.581271e-07   fact   \n",
       "3        0.002143       0.000333   1.018734e-05   2.189004e-06   fact   \n",
       "4        0.000079       0.000005   1.076772e-06   1.921327e-07   fact   \n",
       "5        0.000276       0.000021   2.349377e-06   1.149221e-06   fact   \n",
       "6        0.000275       0.000019   2.907773e-06   2.513672e-07   fact   \n",
       "7        0.002054       0.000491   4.433990e-05   2.830322e-06   fact   \n",
       "8        0.002714       0.000513   2.669943e-05   1.320989e-06   fact   \n",
       "9        0.003489       0.000887   1.010066e-05   1.504882e-06   fact   \n",
       "10       0.003506       0.000494   9.252099e-06   2.927935e-07   fact   \n",
       "11       0.007227       0.001299   9.766759e-05   2.466392e-06   fact   \n",
       "12       0.004176       0.001010   2.276741e-04   8.924300e-07   fact   \n",
       "13       0.000081       0.000006   5.591086e-07   8.553685e-08   fact   \n",
       "14       0.000511       0.000072   5.696230e-06   7.487155e-07   fact   \n",
       "15       0.000774       0.000063   8.536300e-06   1.157843e-06   fact   \n",
       "16       0.000741       0.000084   1.347772e-05   3.984937e-07   fact   \n",
       "17       0.000559       0.000107   1.943385e-05   6.651712e-07   fact   \n",
       "18       0.000391       0.000077   2.381714e-05   1.753440e-06   fact   \n",
       "19       0.000121       0.000032   2.245046e-06   4.598620e-07   fact   \n",
       "\n",
       "             source_file                    file_path  \n",
       "0   logprob_matrix_1.csv  NCT001/logprob_matrix_1.csv  \n",
       "1   logprob_matrix_2.csv  NCT001/logprob_matrix_2.csv  \n",
       "2   logprob_matrix_3.csv  NCT001/logprob_matrix_3.csv  \n",
       "3   logprob_matrix_4.csv  NCT001/logprob_matrix_4.csv  \n",
       "4   logprob_matrix_5.csv  NCT001/logprob_matrix_5.csv  \n",
       "5   logprob_matrix_6.csv  NCT001/logprob_matrix_6.csv  \n",
       "6   logprob_matrix_7.csv  NCT001/logprob_matrix_7.csv  \n",
       "7   logprob_matrix_1.csv  NCT004/logprob_matrix_1.csv  \n",
       "8   logprob_matrix_2.csv  NCT004/logprob_matrix_2.csv  \n",
       "9   logprob_matrix_3.csv  NCT004/logprob_matrix_3.csv  \n",
       "10  logprob_matrix_4.csv  NCT004/logprob_matrix_4.csv  \n",
       "11  logprob_matrix_5.csv  NCT004/logprob_matrix_5.csv  \n",
       "12  logprob_matrix_6.csv  NCT004/logprob_matrix_6.csv  \n",
       "13  logprob_matrix_7.csv  NCT004/logprob_matrix_7.csv  \n",
       "14  logprob_matrix_1.csv  NCT010/logprob_matrix_1.csv  \n",
       "15  logprob_matrix_2.csv  NCT010/logprob_matrix_2.csv  \n",
       "16  logprob_matrix_3.csv  NCT010/logprob_matrix_3.csv  \n",
       "17  logprob_matrix_4.csv  NCT010/logprob_matrix_4.csv  \n",
       "18  logprob_matrix_5.csv  NCT010/logprob_matrix_5.csv  \n",
       "19  logprob_matrix_6.csv  NCT010/logprob_matrix_6.csv  \n",
       "\n",
       "[20 rows x 683 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ffa6459-5ea3-4c9a-b7f0-b7119a5c3151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-63.746"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "row = [-6.88, -100, -11.85, -100, -100]\n",
    "mean= np.mean(row)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ffa3dd3-2a13-4211-80b9-0eb3922d9644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.4297069988088"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std = np.std(row)\n",
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9bb5f3a-597e-4c4c-8240-c01efc3fc0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2799094083948073"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-6.88 - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "639d100f-e1e9-4d00-82a4-041a86c07949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -63.746\n",
      "Std: 44.4297069988088\n",
      "\n",
      "Original value: -6.88\n",
      "Normalized value: 1.2799094083948073\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "row = [-6.88, -100, -11.85, -100, -100]  # Fixed the typo in -11,85\n",
    "\n",
    "# Calculate mean and std of the vector\n",
    "mean = np.mean(row)\n",
    "std = np.std(row)\n",
    "\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"Std: {std}\")\n",
    "\n",
    "# Normalize the first component\n",
    "normalized_value = (row[0] - mean) / std\n",
    "\n",
    "print(f\"\\nOriginal value: {row[0]}\")\n",
    "print(f\"Normalized value: {normalized_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad39c0e1-27d4-41ff-98d7-26cf05f7115e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
